use std::error::Error;
use std::fmt::{self, Display};
use std::io::{self,Write,Read};
use std::collections;
use rand;

use util;

#[derive(Debug)]
pub enum StreamError {
    Io(io::Error),
    /// An error in the container format. If the bool is true, this
    /// error is recoverable
    Format(bool, String),
    Codec(String),
}

impl Display for StreamError {
    fn fmt(&self, fmt: &mut fmt::Formatter) -> Result<(), fmt::Error> {
        write!(fmt, "{:?}", self)
    }
}

impl Error for StreamError {
    fn description(&self) -> &str {
        match *self {
            StreamError::Io(ref err) => err.description(),
            StreamError::Format(_, ref desc) => desc,
            StreamError::Codec(ref desc) => desc,
        }
    }
}

impl From<io::Error> for StreamError {
    fn from(err: io::Error) -> Self {
        StreamError::Io(err)
    }
}

impl Into<io::Error> for StreamError {
    fn into(self) -> io::Error {
        if let StreamError::Io(err) = self {
            err
        } else {
            io::Error::new(io::ErrorKind::Other, self)
        }
    }
}

// Low-level interface

const CRC_LOOKUP : [u32;256] = [
  0x00000000,0x04c11db7,0x09823b6e,0x0d4326d9,
  0x130476dc,0x17c56b6b,0x1a864db2,0x1e475005,
  0x2608edb8,0x22c9f00f,0x2f8ad6d6,0x2b4bcb61,
  0x350c9b64,0x31cd86d3,0x3c8ea00a,0x384fbdbd,
  0x4c11db70,0x48d0c6c7,0x4593e01e,0x4152fda9,
  0x5f15adac,0x5bd4b01b,0x569796c2,0x52568b75,
  0x6a1936c8,0x6ed82b7f,0x639b0da6,0x675a1011,
  0x791d4014,0x7ddc5da3,0x709f7b7a,0x745e66cd,
  0x9823b6e0,0x9ce2ab57,0x91a18d8e,0x95609039,
  0x8b27c03c,0x8fe6dd8b,0x82a5fb52,0x8664e6e5,
  0xbe2b5b58,0xbaea46ef,0xb7a96036,0xb3687d81,
  0xad2f2d84,0xa9ee3033,0xa4ad16ea,0xa06c0b5d,
  0xd4326d90,0xd0f37027,0xddb056fe,0xd9714b49,
  0xc7361b4c,0xc3f706fb,0xceb42022,0xca753d95,
  0xf23a8028,0xf6fb9d9f,0xfbb8bb46,0xff79a6f1,
  0xe13ef6f4,0xe5ffeb43,0xe8bccd9a,0xec7dd02d,
  0x34867077,0x30476dc0,0x3d044b19,0x39c556ae,
  0x278206ab,0x23431b1c,0x2e003dc5,0x2ac12072,
  0x128e9dcf,0x164f8078,0x1b0ca6a1,0x1fcdbb16,
  0x018aeb13,0x054bf6a4,0x0808d07d,0x0cc9cdca,
  0x7897ab07,0x7c56b6b0,0x71159069,0x75d48dde,
  0x6b93dddb,0x6f52c06c,0x6211e6b5,0x66d0fb02,
  0x5e9f46bf,0x5a5e5b08,0x571d7dd1,0x53dc6066,
  0x4d9b3063,0x495a2dd4,0x44190b0d,0x40d816ba,
  0xaca5c697,0xa864db20,0xa527fdf9,0xa1e6e04e,
  0xbfa1b04b,0xbb60adfc,0xb6238b25,0xb2e29692,
  0x8aad2b2f,0x8e6c3698,0x832f1041,0x87ee0df6,
  0x99a95df3,0x9d684044,0x902b669d,0x94ea7b2a,
  0xe0b41de7,0xe4750050,0xe9362689,0xedf73b3e,
  0xf3b06b3b,0xf771768c,0xfa325055,0xfef34de2,
  0xc6bcf05f,0xc27dede8,0xcf3ecb31,0xcbffd686,
  0xd5b88683,0xd1799b34,0xdc3abded,0xd8fba05a,
  0x690ce0ee,0x6dcdfd59,0x608edb80,0x644fc637,
  0x7a089632,0x7ec98b85,0x738aad5c,0x774bb0eb,
  0x4f040d56,0x4bc510e1,0x46863638,0x42472b8f,
  0x5c007b8a,0x58c1663d,0x558240e4,0x51435d53,
  0x251d3b9e,0x21dc2629,0x2c9f00f0,0x285e1d47,
  0x36194d42,0x32d850f5,0x3f9b762c,0x3b5a6b9b,
  0x0315d626,0x07d4cb91,0x0a97ed48,0x0e56f0ff,
  0x1011a0fa,0x14d0bd4d,0x19939b94,0x1d528623,
  0xf12f560e,0xf5ee4bb9,0xf8ad6d60,0xfc6c70d7,
  0xe22b20d2,0xe6ea3d65,0xeba91bbc,0xef68060b,
  0xd727bbb6,0xd3e6a601,0xdea580d8,0xda649d6f,
  0xc423cd6a,0xc0e2d0dd,0xcda1f604,0xc960ebb3,
  0xbd3e8d7e,0xb9ff90c9,0xb4bcb610,0xb07daba7,
  0xae3afba2,0xaafbe615,0xa7b8c0cc,0xa379dd7b,
  0x9b3660c6,0x9ff77d71,0x92b45ba8,0x9675461f,
  0x8832161a,0x8cf30bad,0x81b02d74,0x857130c3,
  0x5d8a9099,0x594b8d2e,0x5408abf7,0x50c9b640,
  0x4e8ee645,0x4a4ffbf2,0x470cdd2b,0x43cdc09c,
  0x7b827d21,0x7f436096,0x7200464f,0x76c15bf8,
  0x68860bfd,0x6c47164a,0x61043093,0x65c52d24,
  0x119b4be9,0x155a565e,0x18197087,0x1cd86d30,
  0x029f3d35,0x065e2082,0x0b1d065b,0x0fdc1bec,
  0x3793a651,0x3352bbe6,0x3e119d3f,0x3ad08088,
  0x2497d08d,0x2056cd3a,0x2d15ebe3,0x29d4f654,
  0xc5a92679,0xc1683bce,0xcc2b1d17,0xc8ea00a0,
  0xd6ad50a5,0xd26c4d12,0xdf2f6bcb,0xdbee767c,
  0xe3a1cbc1,0xe760d676,0xea23f0af,0xeee2ed18,
  0xf0a5bd1d,0xf464a0aa,0xf9278673,0xfde69bc4,
  0x89b8fd09,0x8d79e0be,0x803ac667,0x84fbdbd0,
  0x9abc8bd5,0x9e7d9662,0x933eb0bb,0x97ffad0c,
  0xafb010b1,0xab710d06,0xa6322bdf,0xa2f33668,
  0xbcb4666d,0xb8757bda,0xb5365d03,0xb1f740b4];

fn crc_compute(mut value: u32, block: &[u8]) -> u32 {
    for b in block {
        value = value << 8 ^ CRC_LOOKUP[((value >> 24) as u8 ^ b) as usize];
    }
    value
}

pub struct Packet {
    pub content: Vec<u8>,
    pub timestamp: u64,
}

bitflags!{
    pub flags PageFlags: u8 {
        const PAGE_CTD = 1,
        const PAGE_BOS = 2,
        const PAGE_EOS = 4,
    }
}

// This is perhaps overly whimsical. I am unashamed.
enum ParseResult<V> {
    No, // This is not a valid value
    InsufficientNoms(usize), // Needs at least N total bytes
    Yay(usize, V), // Successful parse. Consumed N bytes
}

// A page backed by an external buffer
pub struct RefPage<'a> {
    pub flags: PageFlags,
    pub granule_position: u64,
    pub stream_serial: u32,
    pub page_sequence: u32,
    pub segment_table: &'a [u8],
    pub content: &'a [u8],
}

impl<'a> RefPage<'a> {
    fn parse(buf: &'a [u8]) -> ParseResult<Self> {
        use byteorder::{LittleEndian,ByteOrder};

        // We need at least 5 bytes to find the signature
        if buf.len() < 5 {
            return ParseResult::InsufficientNoms(5);
        }
        if buf[0..5] != *b"OggS\0" {
            return ParseResult::No;
        }

        // See if we can read the rest of the header
        if buf.len() < 27 {
            return ParseResult::InsufficientNoms(27);
        }
        // Check to see if lacing has been read completely
        let lacing_count = buf[26] as usize;
        if buf.len() < lacing_count + 27 {
            return ParseResult::InsufficientNoms(lacing_count + 27);
        }

        let lacing = &buf[27..27+lacing_count];
        let content_size : usize = lacing.iter().map(|x| *x as usize).sum();
        let target_size = 27 + lacing_count + content_size;
        if buf.len() < target_size {
            return ParseResult::InsufficientNoms(target_size);
        }

        // Check the CRC
        let mut crc = 0;
        crc = crc_compute(crc, &buf[0..22]);
        crc = crc_compute(crc, &[0;4]); // sub in a nulled-out CRC
        crc = crc_compute(crc, &buf[26..27+lacing_count+content_size]);
        let target_crc = LittleEndian::read_u32(&buf[22..26]);
        if crc != target_crc {
            // CRC failed
            return ParseResult::No;
        }

        ParseResult::Yay(target_size, RefPage{
            flags: PageFlags::from_bits_truncate(buf[5]),
            granule_position: LittleEndian::read_u64(&buf[6..14]),
            stream_serial: LittleEndian::read_u32(&buf[14..18]),
            page_sequence: LittleEndian::read_u32(&buf[18..22]),
            segment_table: lacing,
            content: &buf[27+lacing_count..target_size],
        })
    }

    fn packets(&self) -> Packets {
        Packets{
            segment_iter: self.segment_table.iter(),
            content: self.content,
            byte_off: 0,
        }
    }
}

/// Iterator over packets within a page. The bool that is returned as
/// well indicates whether the packet is complete.
pub struct Packets<'a> {
    segment_iter: ::std::slice::Iter<'a, u8>,
    content: &'a [u8],
    byte_off: usize,
}

impl <'a> Iterator for Packets<'a> {
    type Item = (&'a [u8], bool);

    fn next(&mut self) -> Option<Self::Item> {
        let start = self.byte_off;
        let mut had_iter = false;
        for s in self.segment_iter.by_ref() {
            had_iter = true;
            self.byte_off += *s as usize;
            if *s != 255 {
                return Some((&self.content[start..self.byte_off], true));
            }
        }
        if had_iter {
            Some((&self.content[start..self.byte_off], false))
        } else {
            None
        }
    }
}   


pub struct Page {
    pub flags: PageFlags,
    pub granule_position: u64,
    pub stream_serial: u32,
    pub page_sequence: u32,
    /// The last element is the number of elements used
    pub segment_table: Vec<u8>,
    pub content: Vec<u8>,
}

impl Page {
    pub fn new(stream_serial: u32, sequence: u32) -> Self {
        Page{
            flags: PageFlags::empty(),
            granule_position: !0,
            stream_serial: stream_serial,
            page_sequence: sequence,
            segment_table: Vec::new(),
            content: Vec::new(),
        }
    }

    pub fn write_to<W: Write>(&self, writer: &mut W) -> io::Result<()> {
        use byteorder::{LittleEndian,ByteOrder};
        let mut header = [0;27];
        header[0..5].copy_from_slice(b"OggS\0");
        header[5] = self.flags.bits();
        LittleEndian::write_u64(&mut header[6..14], self.granule_position);
        LittleEndian::write_u32(&mut header[14..18], self.stream_serial);
        LittleEndian::write_u32(&mut header[18..22], self.page_sequence);
        // leave checksum in 22..26 blank
        header[26] = self.segment_table.len() as u8;

        let mut crc = 0;
        crc = crc_compute(crc, &header);
        crc = crc_compute(crc, &self.segment_table);
        crc = crc_compute(crc, &self.content);
        LittleEndian::write_u32(&mut header[22..26], crc);

        try!(writer.write_all(&header));
        try!(writer.write_all(&self.segment_table));
        try!(writer.write_all(&self.content));
        Ok(())
    }

    fn add_segment(&mut self, segment: &[u8]) {
        assert!(segment.len() < 256);
        assert!(self.segment_table.len() < 255);
        self.segment_table.push(segment.len() as u8);
        self.content.extend_from_slice(segment);
    }

    fn has_space(&self) -> bool {
        self.segment_table.len() < 255
    }

    /// Add the part of packet that starts at offset.  If there is
    /// already data in this packet, offset MUST be 0.
    ///
    /// # Returns
    ///
    /// None: The packet was completely written and the next packet
    /// may be written immediately.
    ///
    /// Some(n): There was insufficent space to write the packet, and
    /// the same packet should be added to a new frame, passing n as
    /// offset.
    fn add_packet(&mut self, packet: &Packet, offset: usize) -> Option<usize> {
        let mut offset = offset;
        let plen = packet.content.len();
        if offset != 0 {
            assert!(self.segment_table.len() == 0);
            assert!(!self.flags.intersects(PAGE_BOS));
            self.flags |= PAGE_CTD;
        }
        while plen - offset > 254 && self.has_space() {
            // Write a 255-byte segment
            self.add_segment(&packet.content[offset..offset+255]);
            offset += 255;
        }
        if self.has_space() {
            // write final chunk
            assert!(plen - offset < 255);
            self.add_segment(&packet.content[offset..]);
            self.granule_position = packet.timestamp;
            None
        } else {
            Some(offset)
        }
    }

    pub fn content_size(&self) -> usize {
        self.segment_table.iter().map(|x| *x as usize).sum()
    }
}

// Page packer
pub struct PagePacker {
    page_queue : collections::VecDeque<Page>,

    // This is only none when the stream is closed
    active_page: Option<Page>,

    stream_serial: u32,
    page_sequence: u32,
}

impl PagePacker {
    pub fn new(serial: u32) -> Self {
        let mut start_page = Page::new(serial, 0);
        start_page.flags |= PAGE_BOS;
        PagePacker{
            page_queue: collections::VecDeque::new(),
            active_page: Some(start_page),
            stream_serial: serial,
            page_sequence: 0,
        }
    }

    // Immediately emit the current page and prepare the next one
    pub fn emit(&mut self) {
        // Emit a page and get the next page ready
        if let Some(page) = self.active_page.take() {
            let eos = page.flags.intersects(PAGE_EOS);
            self.page_queue.push_back(page);
            if !eos {
                self.page_sequence += 1;
                self.active_page = Some(Page::new(self.stream_serial, self.page_sequence));
            }
        }
    }

    fn get_active(&mut self) -> &mut Page {
        match self.active_page.as_mut() {
            None => panic!("Attempted to add packets to a closed stream"),
            Some(page) => page,
        }
    }

    pub fn add_packet(&mut self, packet: &Packet) {
        let mut offset = Some(0);
        while let Some(off) = offset {
            offset = self.get_active().add_packet(packet, off);
            if offset.is_some() {
                self.emit()
            }
        }
        // TODO: Limit page size?
        //if self.get_active().content_size() > 8192 {
        //self.emit()
        //}
    }

    pub fn close(&mut self) {
        self.get_active().flags |= PAGE_EOS;
        self.emit();
        assert!(self.active_page.is_none());
    }

    pub fn is_closed(&self) -> bool {
        self.active_page.is_none()
    }

    pub fn peek_next(&self) -> Option<&Page> {
        self.page_queue.front()
    }

    pub fn take_next(&mut self) -> Option<Page> {
        self.page_queue.pop_front()
    }
}

pub trait BitstreamCoder {
    fn headers(&self) -> Vec<Vec<u8>>;
    fn next_frame(&mut self) -> io::Result<Option<Packet>>;

    /// Map a granule position to an absolute timestamp in µs
    fn map_granule(&self, u64) -> u64;
}

struct MuxStream {
    bitstream: Box<BitstreamCoder>,
    packer: PagePacker,
}

impl MuxStream {
    fn pump(&mut self) -> io::Result<()> {
        while self.packer.peek_next().is_none() && !self.packer.is_closed() {
            if let Some(frame) = try!(self.bitstream.next_frame()) {
                self.packer.add_packet(&frame);
                // TODO: Emit early for lower bufferring needs
            } else {
                self.packer.close();
            }
        }
        Ok(())
    }

    fn is_live(&self) -> bool {
        self.packer.peek_next().is_some() || !self.packer.is_closed()
    }
}

// Muxer
pub struct OgkMux {
    streams: Vec<MuxStream>,
}

impl Default for OgkMux {
    fn default() -> Self { Self::new() }
}

impl OgkMux {
    pub fn new() -> Self {
        OgkMux{
            streams: Vec::new(),
        }
    }

    pub fn add_stream(&mut self, stream: Box<BitstreamCoder>) {
        let serial = rand::random();
        self.streams.push(MuxStream{
            bitstream: stream,
            packer: PagePacker::new(serial),
        })
    }

    pub fn write_to<W: io::Write>(&mut self, mut w: W) -> io::Result<()> {
        // Write headers...
        for stream in &mut self.streams {
            let headers = stream.bitstream.headers();
            let first_packet = try!(stream.bitstream.next_frame());
            let header_count = headers.len();
            let mut it = headers.into_iter();
            stream.packer.add_packet(&Packet{content: it.next().expect("Streams must contain at least one header"), timestamp: 0});
            // Produce additional headers, if any
            if header_count > 1 {
                stream.packer.emit();
                for header in it {
                    stream.packer.add_packet(&Packet{content: header, timestamp: 0});
                }
            }
            // Close the stream
            if let Some(packet) = first_packet {
                stream.packer.emit();
                stream.packer.add_packet(&packet);
            } else {
                stream.packer.close();
            }
            try!(stream.packer.take_next().unwrap().write_to(&mut w));
        }

        // Write the remaining header packets
        for stream in &mut self.streams {
            while let Some(frame) = stream.packer.take_next() {
                try!(frame.write_to(&mut w));
            }
        }

        for stream in &mut self.streams {
            try!(stream.pump());
        }

        loop {
            self.streams.retain(MuxStream::is_live);
            if self.streams.is_empty() {
                break;
            }
            if let Some(stream) = self.streams.iter_mut().min_by_key(|stream| stream.bitstream.map_granule(stream.packer.peek_next().unwrap().granule_position)) {
                try!(stream.packer.take_next().unwrap().write_to(&mut w));
                try!(stream.pump());
            } else {
                panic!("This should be unreachable");
            }
        }
        Ok(())
    }
}

// Demuxer

pub trait BitstreamDecoder {
    /// Map a granule position to a timestamp, in µs
    fn map_granule(&self, u64) -> u64;

    /// Returns the total number of headers in the stream
    fn num_headers(&self) -> usize;

    /// Called to process each header packet except the first
    fn process_header(&mut self, &[u8]);

    /// Called for each packet in the stream. Returns the granule position of this packet
    fn process_packet(&mut self, packet: &[u8], last_granule: u64) -> u64;

    /// There was a gap in the underlying page stream. May be called
    /// multiple times in a row; should therefore be idempotent.
    // This will happen when we regain sync on a page that contains a
    // single 65025-byte segment and the CTD bit set
    fn notice_gap(&mut self);
    
    /// Called at the end of the stream. This is guaranteed to be
    /// called before the page is finished being processed.
    fn finish(&mut self);
}

struct StreamState<Desc> {
    decoder: Box<BitstreamDecoder>,
    
    /// The prefix of a partial packet
    partial: Vec<u8>,
    
    /// The last granule that has been read
    hwm: u64,
    
    /// The last page sequence number seen
    last_page_seq: u32,

    /// Number of remaining header packets
    headers_remaining: usize,

    /// EOS packet seen
    finished: bool,
    
    /// This holds user data associated with the stream, such as decode buffers
    user_data: Desc,
}

impl <Desc> StreamState<Desc> {
    pub fn process_page(&mut self, page: RefPage) -> Result<(), StreamError> {
        let had_gap = page.page_sequence != self.last_page_seq + 1;
        if had_gap {
            if page.segment_table.iter().filter(|x| **x != 255).count() == 0 {
                // This page doesn't have any packets that finish on it.
                return Ok(());
            }
            self.decoder.notice_gap();
        }
        
        self.last_page_seq = page.page_sequence;

        for (i, (packet, completep)) in page.packets().enumerate() {
            let packet_continued = i == 0 && page.flags.intersects(PAGE_CTD);
            if had_gap && packet_continued {
                // We do nothing with an incomplete packet
                continue;
            }
            
            if !packet_continued {
                self.partial.clear();
            }

            if !completep {
                self.partial.extend_from_slice(packet);
                break;
            } else {
                // Get a reference to the packet body
                let packet_ref = if packet_continued {
                    &self.partial
                } else {
                    packet
                };

                // process it
                if self.headers_remaining > 0 {
                    self.headers_remaining -= 1;
                    self.decoder.process_header(packet);
                } else {
                    self.hwm = self.decoder.process_packet(packet_ref, self.hwm);
                }
            }
        }

        if page.flags.intersects(PAGE_EOS) {
            self.decoder.finish();
            self.finished = true;
        }

        Ok(())
    }
}


pub struct OggPageSource<R> {
    buffer: util::ShiftBuffer,
    reader: R,
    dead_bytes: usize,
    eof: bool,
}

// TODO: When nonlexical lifetimes land, kill this with fire.
unsafe fn unalias<'a,'b, E: ?Sized>(elem: &'a E) -> &'b E {
    &*(elem as *const E)
}

impl <R: Read> OggPageSource<R> {
    pub fn next_page(&mut self) -> Result<Option<RefPage>, StreamError> {
        loop {
            self.buffer.consume(self.dead_bytes);
            self.dead_bytes = 0;
            if try!(self.buffer.fill_max(&mut self.reader)) == 0 {
                self.eof = true;
                return Ok(None);
            }
            for i in 0..self.buffer.len() - 5 {
                // Try to parse...  The unsafe unalias simply divorces
                // the borrow of buffer from the lifetime of this
                // function, so that the loop still works.
                match RefPage::parse(unsafe{unalias(&self.buffer[i..])}) {
                    ParseResult::No => { println!("Skipping"); continue; },
                    ParseResult::InsufficientNoms(_) => {
                        if i == 0 {
                            if self.buffer.is_empty() {
                                self.eof = true;
                                return Ok(None);
                            }
                            //println!("EOF at offset {}; need {} had {} (contents {})", self.buffer.offset(), n, self.buffer.len(), &self.buffer[..].iter().map(|x| format!("{:02x}", x)).collect::<Vec<String>>().join(""));
                            // We'll never be able to complete this page
                            return Err(StreamError::Io(io::Error::new(io::ErrorKind::UnexpectedEof, "Incomplete page")));
                        }
                        self.dead_bytes = i;
                        break;
                    },
                    ParseResult::Yay(n, page_res) => {
                        // handle the page
                        self.dead_bytes = i + n;
                        return Ok(Some(page_res));
                    }
                }
            }
        }
    }

    pub fn is_eof(&self) -> bool {
        self.eof
    }
}

pub type StreamInitFn<StreamDesc> = Fn(&[u8]) -> Option<(Box<BitstreamDecoder>, StreamDesc)>;

struct StreamMapper<StreamDesc>{
    streams: collections::HashMap<u32, StreamState<StreamDesc>>,
    discard_streams: collections::HashSet<u32>,
    // This just refers to the BOS headers.
    headers_read: bool,

    /// High water mark. This is in µs rather than a granule position
    /// as in StreamState
    hwm: u64,

    /// A function to identify a stream given its first header
    /// packet. Should return a decoder for that stream as well as a
    /// user-defined data value that must be the same type across all
    /// streams within a demux
    stream_init: Box<StreamInitFn<StreamDesc>>,
}

impl<StreamDesc> StreamMapper<StreamDesc> {
    #[allow(needless_return)] // This is a long enough function that I'll give it a pass.
    fn handle_page(&mut self, page: RefPage) -> Result<(),StreamError> {
        use std::collections::hash_map::Entry;
        if self.discard_streams.contains(&page.stream_serial) {
            return Ok(());
        }
        if page.flags.intersects(PAGE_BOS) {
            match self.streams.entry(page.stream_serial) {
                Entry::Occupied(_) => return Err(StreamError::Format(true, "Stream has multiple BOS pages".to_owned())),
                Entry::Vacant(e) => {
                    let packet = {
                        if let Some((packet, complete)) = page.packets().next() {
                            if !complete {
                                self.discard_streams.insert(page.stream_serial);
                                return Err(StreamError::Format(true, "Initial header packet too large for first page".to_owned()));
                            }
                            packet
                        } else {
                            self.discard_streams.insert(page.stream_serial);
                            return Err(StreamError::Format(true, "BOS page had no packet".to_owned()));
                        }
                    };
                    if let Some((mut decoder, desc)) = (self.stream_init)(packet) {
                        if page.flags.intersects(PAGE_EOS) {
                            decoder.finish();
                        }
                        let num_headers = decoder.num_headers();
                        e.insert(StreamState{
                            decoder: decoder,
                            partial: Vec::new(),
                            hwm: 0,
                            last_page_seq: page.page_sequence,
                            user_data: desc,
                            headers_remaining: num_headers - 1,
                            finished: page.flags.intersects(PAGE_EOS),
                        });
                        return Ok(());
                    } else {
                        self.discard_streams.insert(page.stream_serial);
                        return Ok(());
                    }
                }
            }
        } else {
            self.headers_read = true;
            // Mid-stream
            if let Some(state) = self.streams.get_mut(&page.stream_serial) {
                try!(state.process_page(page));
                let hwm = state.decoder.map_granule(state.hwm);
                self.hwm = ::std::cmp::max(self.hwm, hwm);
                return Ok(());
            } else {
                self.discard_streams.insert(page.stream_serial);
                return Err(StreamError::Format(true, format!("Stream {} had no BOS packet", page.stream_serial)));
            }
        }
    }

    fn lwm(&self) -> u64 {
        self.streams.values().map(|stream| stream.decoder.map_granule(stream.hwm)).min().unwrap_or(0)
    }

    fn discard(&mut self, id: u32) {
        self.discard_streams.insert(id);
    }
}


pub struct OggDemux<R, StreamDesc> {
    source: OggPageSource<R>,
    mapper: StreamMapper<StreamDesc>,
}

impl <R: Read, StreamDesc> OggDemux<R, StreamDesc> {
    pub fn new<F>(reader: R, stream_mapper: F) -> Result<Self, StreamError>
        where F: 'static + Fn(&[u8]) -> Option<(Box<BitstreamDecoder>, StreamDesc)>
    {
        let mut demux = OggDemux{
            source: OggPageSource{
                buffer: util::ShiftBuffer::new(65536),
                reader: reader,
                dead_bytes: 0,
                eof: false,
            },
            mapper: StreamMapper{
                streams: collections::HashMap::new(),
                discard_streams: collections::HashSet::new(),
                headers_read: false,
                hwm: 0,
                stream_init: Box::new(stream_mapper),
            },
        };

        //while !demux.mapper.headers_read && !demux.source.is_eof() {
        //    try!(demux.pump_page());
        //}

        try!(demux.internal_pump_until(|ogg| ogg.mapper.headers_read));

        Ok(demux)
    }

    fn internal_pump_until<F>(&mut self, predicate: F) -> Result<(), StreamError>
        where F: Fn(&Self) -> bool
    {
        while !predicate(self) && !self.source.is_eof() {
            try!(self.pump_page());
        }
        Ok(())
    }
    
    pub fn is_eof(&self) -> bool {
        self.source.is_eof()
    }
    
    pub fn pump_page(&mut self) -> Result<(), StreamError> {
        if let Some(page) = try!(self.source.next_page()) {
            let page_ser = page.stream_serial;
            try!(self.mapper.handle_page(page));
            println!("Pumped a page for stream {:x}", page_ser);
        }
        Ok(())
    }

    pub fn streams<'a>(&'a mut self) -> DemuxStreams<StreamDesc> {
        DemuxStreams(self.mapper.streams.iter_mut())
    }

    /// Takes time in µs
    pub fn pump_until(&mut self, time: u64) -> Result<u64, StreamError> {
        try!(self.internal_pump_until(|ogg| ogg.mapper.lwm() >= time));
        Ok(self.mapper.hwm)
    }

    pub fn ignore_stream(&mut self, id: u32) {
        self.mapper.discard(id)
    }
}

pub struct DemuxStreams<'a, Desc: 'a>(collections::hash_map::IterMut<'a, u32, StreamState<Desc>>);

impl <'a, Desc> Iterator for DemuxStreams<'a, Desc> {
    type Item = (u32, &'a mut Desc);

    fn next(&mut self) -> Option<(u32, &'a mut Desc)> {
        self.0.next().map(|(id,state)| (*id, &mut state.user_data))
    }
}


